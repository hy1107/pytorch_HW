{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kc8YEieZRCO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzVVX0apZaBr",
        "outputId": "a45e3b01-b022-47a4-ef66-4679fbdb967b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NDKMZ5KBZZ_F",
        "outputId": "aac4204f-2ffb-4992-9e48-b5991275f05f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-8f445aac-8258-495c-a151-bdb5f42fc298\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>pop</th>\n",
              "      <th>pop2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1950</td>\n",
              "      <td>2.53</td>\n",
              "      <td>0.557959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1951</td>\n",
              "      <td>2.57</td>\n",
              "      <td>0.861880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1952</td>\n",
              "      <td>2.62</td>\n",
              "      <td>0.747475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1953</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.801511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1954</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.851062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f445aac-8258-495c-a151-bdb5f42fc298')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e6017354-5755-4e53-a051-192d1307c98c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6017354-5755-4e53-a051-192d1307c98c')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e6017354-5755-4e53-a051-192d1307c98c button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f445aac-8258-495c-a151-bdb5f42fc298 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f445aac-8258-495c-a151-bdb5f42fc298');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   year   pop      pop2\n",
              "0  1950  2.53  0.557959\n",
              "1  1951  2.57  0.861880\n",
              "2  1952  2.62  0.747475\n",
              "3  1953  2.67  0.801511\n",
              "4  1954  2.71  0.851062"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('population.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "2Jt82yBDZZ7b",
        "outputId": "cdfd4b4d-efad-4566-d667-836c9ad4a043"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df2 = df.set_index('year')\n",
        "df2.plot(legend=None)\n",
        "plt.xticks(rotation=30);\n",
        "# 橘 pop 、藍 pop2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "hbzU3ndca9FP",
        "outputId": "50d3d89e-47f8-4e63-a1cc-42f0184d2a5b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-07b48222-84f6-4a67-94ac-a91839b44a5f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pop</th>\n",
              "      <th>pop2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>2.53</td>\n",
              "      <td>0.557959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1951</th>\n",
              "      <td>2.57</td>\n",
              "      <td>0.861880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>2.62</td>\n",
              "      <td>0.747475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>2.67</td>\n",
              "      <td>0.801511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1954</th>\n",
              "      <td>2.71</td>\n",
              "      <td>0.851062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07b48222-84f6-4a67-94ac-a91839b44a5f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8c369100-8a84-4a94-8829-0ff0aa56f37e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c369100-8a84-4a94-8829-0ff0aa56f37e')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8c369100-8a84-4a94-8829-0ff0aa56f37e button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-07b48222-84f6-4a67-94ac-a91839b44a5f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-07b48222-84f6-4a67-94ac-a91839b44a5f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "       pop      pop2\n",
              "year                \n",
              "1950  2.53  0.557959\n",
              "1951  2.57  0.861880\n",
              "1952  2.62  0.747475\n",
              "1953  2.67  0.801511\n",
              "1954  2.71  0.851062"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "nhBXBEXWbfap",
        "outputId": "4f8c742d-fac0-4cab-b472-9842379679ce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c95abe78-a746-42ef-bf3f-9be225def829\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pop</th>\n",
              "      <th>pop2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2096</th>\n",
              "      <td>10.81</td>\n",
              "      <td>0.798702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2097</th>\n",
              "      <td>10.82</td>\n",
              "      <td>0.600868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2098</th>\n",
              "      <td>10.83</td>\n",
              "      <td>0.720714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2099</th>\n",
              "      <td>10.84</td>\n",
              "      <td>0.844270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2100</th>\n",
              "      <td>10.85</td>\n",
              "      <td>0.469745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c95abe78-a746-42ef-bf3f-9be225def829')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-864245a7-1fe0-4405-ab90-9dc88f2b0721\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-864245a7-1fe0-4405-ab90-9dc88f2b0721')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-864245a7-1fe0-4405-ab90-9dc88f2b0721 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c95abe78-a746-42ef-bf3f-9be225def829 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c95abe78-a746-42ef-bf3f-9be225def829');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        pop      pop2\n",
              "year                 \n",
              "2096  10.81  0.798702\n",
              "2097  10.82  0.600868\n",
              "2098  10.83  0.720714\n",
              "2099  10.84  0.844270\n",
              "2100  10.85  0.469745"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_jq4Q2FZZ5Y",
        "outputId": "1eb03136-6195-48a6-a1c2-98facd0967eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0MZuCYjZZ3S",
        "outputId": "9f848634-2b65-4fb1-d6b5-de8fbd72fe32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this 0 round [[0.        0.5573713]] [0.8618545]\n",
            "this 1 round [[0.00480768 0.8618545 ]] [0.7472375]\n",
            "this 2 round [[0.01081729 0.7472375 ]] [0.8013733]\n",
            "this 3 round [[0.01682693 0.8013733 ]] [0.8510159]\n",
            "this 4 round [[0.02163461 0.8510159 ]] [0.06202664]\n",
            "this 5 round [[0.02764422 0.06202664]] [0.93627787]\n",
            "this 6 round [[0.03365386 0.93627787]] [0.15169778]\n",
            "this 7 round [[0.03966346 0.15169778]] [0.9813841]\n",
            "this 8 round [[0.046875  0.9813841]] [0.7808319]\n",
            "this 9 round [[0.05288461 0.7808319 ]] [0.6458696]\n",
            "this 10 round [[0.06009614 0.6458696 ]] [0.6639264]\n",
            "this 11 round [[0.06610575 0.6639264 ]] [0.7386251]\n",
            "this 12 round [[0.07331732 0.7386251 ]] [0.34845677]\n",
            "this 0 round [[0.09615383 0.19263187]] [0.4389116]\n",
            "this 1 round [[0.10456732 0.4389116 ]] [0.73858386]\n",
            "this 2 round [[0.11298075 0.73858386]] [0.7782367]\n",
            "this 3 round [[0.12139422 0.7782367 ]] [0.76726466]\n",
            "this 4 round [[0.13100961 0.76726466]] [0.08639757]\n",
            "this 5 round [[0.13942307 0.08639757]] [0.32415608]\n",
            "this 6 round [[0.14903846 0.32415608]] [0.05943961]\n",
            "this 7 round [[0.1574519  0.05943961]] [0.6242529]\n",
            "this 8 round [[0.16706732 0.6242529 ]] [0.44256893]\n",
            "this 9 round [[0.17668268 0.44256893]] [0.9458539]\n",
            "this 10 round [[0.18509617 0.9458539 ]] [0.46564683]\n",
            "this 11 round [[0.19471154 0.46564683]] [0.5471222]\n",
            "this 12 round [[0.20312494 0.5471222 ]] [0.29796195]\n",
            "this 13 round [[0.21274042 0.29796195]] [0.15564518]\n",
            "this 14 round [[0.2211538  0.15564518]] [0.03083928]\n",
            "this 15 round [[0.23076922 0.03083928]] [0.24949051]\n",
            "this 16 round [[0.24038464 0.24949051]] [0.9598502]\n",
            "this 17 round [[0.25      0.9598502]] [0.7132297]\n",
            "this 18 round [[0.25961536 0.7132297 ]] [0.7927541]\n",
            "this 19 round [[0.2704327 0.7927541]] [0.00241306]\n",
            "this 20 round [[0.28004807 0.00241306]] [0.2440945]\n",
            "this 21 round [[0.29086536 0.2440945 ]] [0.7726663]\n",
            "this 22 round [[0.30288464 0.7726663 ]] [0.84400314]\n",
            "this 23 round [[0.31370187 0.84400314]] [0.80433756]\n",
            "this 24 round [[0.32451922 0.80433756]] [0.156383]\n",
            "this 25 round [[0.3353365 0.156383 ]] [0.62426955]\n",
            "this 26 round [[0.3461538  0.62426955]] [0.629612]\n",
            "this 27 round [[0.35576916 0.629612  ]] [0.9192659]\n",
            "this 28 round [[0.3665865 0.9192659]] [0.43116057]\n",
            "this 29 round [[0.37620187 0.43116057]] [0.02244443]\n",
            "this 30 round [[0.38581723 0.02244443]] [0.10792887]\n",
            "this 31 round [[0.3954327  0.10792887]] [0.3024755]\n",
            "this 32 round [[0.40504807 0.3024755 ]] [0.06978489]\n",
            "this 33 round [[0.41466343 0.06978489]] [0.80973816]\n",
            "this 34 round [[0.42307693 0.80973816]] [0.77751327]\n",
            "this 35 round [[0.4326923  0.77751327]] [0.6067704]\n",
            "this 36 round [[0.44110572 0.6067704 ]] [0.73545164]\n",
            "this 37 round [[0.45072114 0.73545164]] [0.01534038]\n",
            "this 38 round [[0.4603365  0.01534038]] [0.99999994]\n",
            "this 39 round [[0.46995187 0.99999994]] [0.28472555]\n",
            "this 40 round [[0.47836536 0.28472555]] [0.98815644]\n",
            "this 41 round [[0.48798072 0.98815644]] [0.9541037]\n",
            "this 42 round [[0.49759614 0.9541037 ]] [0.30543342]\n",
            "this 43 round [[0.5072115  0.30543342]] [0.6357594]\n",
            "this 44 round [[0.51682687 0.6357594 ]] [0.47152558]\n",
            "this 45 round [[0.5276442  0.47152558]] [0.86968577]\n",
            "this 46 round [[0.5372596  0.86968577]] [0.51460373]\n",
            "this 47 round [[0.54687494 0.51460373]] [0.11521232]\n",
            "this 48 round [[0.5564903  0.11521232]] [0.19899699]\n",
            "this 49 round [[0.5661057  0.19899699]] [0.9748522]\n",
            "this 50 round [[0.57572114 0.9748522 ]] [0.26430944]\n",
            "this 51 round [[0.5853365  0.26430944]] [0.44467708]\n",
            "this 52 round [[0.59495187 0.44467708]] [0.98716646]\n",
            "this 53 round [[0.6045672  0.98716646]] [0.02804065]\n",
            "this 54 round [[0.61418265 0.02804065]] [0.36728576]\n",
            "this 55 round [[0.623798   0.36728576]] [0.19262093]\n",
            "this 56 round [[0.6322115  0.19262093]] [0.71245337]\n",
            "this 57 round [[0.64182687 0.71245337]] [0.28164813]\n",
            "this 58 round [[0.65024036 0.28164813]] [0.75588655]\n",
            "this 59 round [[0.6586538  0.75588655]] [0.01686989]\n",
            "this 60 round [[0.6670672  0.01686989]] [0.51484555]\n",
            "this 61 round [[0.67548066 0.51484555]] [0.8753587]\n",
            "this 62 round [[0.6838942 0.8753587]] [0.2053057]\n",
            "this 63 round [[0.69230765 0.2053057 ]] [0.5796399]\n",
            "this 64 round [[0.7007211 0.5796399]] [0.38757464]\n",
            "this 65 round [[0.70793265 0.38757464]] [0.30321074]\n",
            "this 66 round [[0.7163461  0.30321074]] [0.96169776]\n",
            "this 67 round [[0.72475964 0.96169776]] [0.00850468]\n",
            "this 68 round [[0.7319711  0.00850468]] [0.88994086]\n",
            "this 69 round [[0.73918265 0.88994086]] [0.04809418]\n",
            "this 70 round [[0.7463941  0.04809418]] [0.85399175]\n",
            "this 71 round [[0.7536058  0.85399175]] [0.20621696]\n",
            "this 72 round [[0.7608172  0.20621696]] [0.76961523]\n",
            "this 73 round [[0.7680288  0.76961523]] [0.69812566]\n",
            "this 74 round [[0.77524024 0.69812566]] [0.6416146]\n",
            "this 75 round [[0.7824518 0.6416146]] [0.40532574]\n",
            "this 76 round [[0.7884615  0.40532574]] [0.5455075]\n",
            "this 77 round [[0.79567295 0.5455075 ]] [0.79042107]\n",
            "this 78 round [[0.80168265 0.79042107]] [0.43995368]\n",
            "this 79 round [[0.8088942  0.43995368]] [0.32242626]\n",
            "this 80 round [[0.8149038  0.32242626]] [0.75614345]\n",
            "this 81 round [[0.8209134  0.75614345]] [0.44441882]\n",
            "this 82 round [[0.82692295 0.44441882]] [0.6508899]\n",
            "this 83 round [[0.83293265 0.6508899 ]] [0.9377337]\n",
            "this 84 round [[0.83774036 0.9377337 ]] [0.17814256]\n",
            "this 85 round [[0.84374994 0.17814256]] [0.89097476]\n",
            "this 86 round [[0.84975964 0.89097476]] [0.19462807]\n",
            "this 87 round [[0.8545672  0.19462807]] [0.12416975]\n",
            "this 88 round [[0.85937494 0.12416975]] [0.18080804]\n",
            "this 89 round [[0.8653845  0.18080804]] [0.9902304]\n",
            "this 90 round [[0.8701922 0.9902304]] [0.26959604]\n",
            "this 91 round [[0.87499994 0.26959604]] [0.9787115]\n",
            "this 92 round [[0.87980765 0.9787115 ]] [0.5516271]\n",
            "this 93 round [[0.8834134 0.5516271]] [0.30721098]\n",
            "this 94 round [[0.8882211  0.30721098]] [0.01793537]\n",
            "this 95 round [[0.8930288  0.01793537]] [0.92577475]\n",
            "this 96 round [[0.8966345  0.92577475]] [0.34309143]\n",
            "this 97 round [[0.9014422  0.34309143]] [0.5309037]\n",
            "this 98 round [[0.9050481 0.5309037]] [0.42252648]\n",
            "this 99 round [[0.9086538  0.42252648]] [0.79299]\n",
            "this 100 round [[0.9134615 0.79299  ]] [0.54231584]\n",
            "this 101 round [[0.9170672  0.54231584]] [0.5541436]\n",
            "this 102 round [[0.92067295 0.5541436 ]] [0.41513857]\n",
            "this 103 round [[0.9242788  0.41513857]] [0.12493137]\n",
            "this 104 round [[0.9278845  0.12493137]] [0.84483767]\n",
            "this 105 round [[0.93149024 0.84483767]] [0.00138295]\n",
            "this 106 round [[0.9350961  0.00138295]] [0.35860327]\n",
            "this 107 round [[0.93749994 0.35860327]] [0.2012381]\n",
            "this 108 round [[0.94110566 0.2012381 ]] [0.8075516]\n",
            "this 109 round [[0.9435095 0.8075516]] [0.05732105]\n",
            "this 110 round [[0.94711524 0.05732105]] [0.15128945]\n",
            "this 111 round [[0.9495192  0.15128945]] [0.5774048]\n",
            "this 112 round [[0.95312494 0.5774048 ]] [0.33490384]\n",
            "this 113 round [[0.9555287  0.33490384]] [0.]\n",
            "this 114 round [[0.95793265 0.        ]] [0.15846674]\n",
            "this 115 round [[0.9603365  0.15846674]] [0.1311672]\n",
            "this 116 round [[0.9639422 0.1311672]] [0.8242274]\n",
            "this 117 round [[0.9663461 0.8242274]] [0.14319758]\n",
            "this 118 round [[0.96874994 0.14319758]] [0.93006074]\n",
            "this 119 round [[0.9711537  0.93006074]] [0.34759566]\n",
            "this 120 round [[0.97355765 0.34759566]] [0.9383581]\n",
            "this 121 round [[0.9759614 0.9383581]] [0.11111671]\n",
            "this 122 round [[0.9771634  0.11111671]] [0.9217503]\n",
            "this 123 round [[0.9795672 0.9217503]] [0.9514163]\n",
            "this 124 round [[0.9819711 0.9514163]] [0.28583276]\n",
            "this 125 round [[0.98437494 0.28583276]] [0.5627077]\n",
            "this 126 round [[0.9855768 0.5627077]] [0.865321]\n",
            "this 127 round [[0.98798066 0.865321  ]] [0.19378155]\n",
            "this 128 round [[0.99038464 0.19378155]] [0.33249417]\n",
            "this 129 round [[0.9915864  0.33249417]] [0.26080313]\n",
            "this 130 round [[0.9927884  0.26080313]] [0.7985593]\n",
            "this 131 round [[0.9951922 0.7985593]] [0.6003598]\n",
            "this 132 round [[0.9963941 0.6003598]] [0.720427]\n",
            "this 133 round [[0.9975961 0.720427 ]] [0.8442117]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(151, 2)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "look_back = 1 # 以前N期资料为 X，当期资料为 Y\n",
        "\n",
        "# 函数：以前N期资料为 X，当前期资料为 Y\n",
        "def create_dataset(data1, look_back):\n",
        "    x, y = [], []\n",
        "    for i in range(len(data1)-look_back-1):\n",
        "        _x = data1[i:(i+look_back)]\n",
        "        _y = data1[i+look_back, 1:2]\n",
        "        print(f'this {i} round', _x, _y)\n",
        "        x.append(_x)\n",
        "        y.append(_y)\n",
        "\n",
        "    return torch.Tensor(np.array(x)), torch.Tensor(np.array(y))\n",
        "\n",
        "dataset = df2[['pop', 'pop2']].values.astype('float32')\n",
        "\n",
        "# X 常态化\n",
        "scaler = MinMaxScaler()\n",
        "dataset = scaler.fit_transform(dataset)\n",
        "\n",
        "# 资料分割\n",
        "train_size = int(len(dataset) * 0.1) # int(151 * 0.1) => 15 : train_size\n",
        "test_size = len(dataset) - train_size # test_size = 151 - 15 = 136\n",
        "train_data, test_data = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "\n",
        "trainX, trainY = create_dataset(train_data, look_back)\n",
        "testX, testY = create_dataset(test_data, look_back)\n",
        "dataset.shape#, trainY.shape, testY.shape,trainX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoGNAo1BZZ07",
        "outputId": "eac4a8ad-1f05-4299-8f1a-922f30a8406a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([13, 1, 2]),\n",
              " torch.Size([13, 1]),\n",
              " torch.Size([134, 1, 2]),\n",
              " torch.Size([134, 1]),\n",
              " torch.Size([1, 2]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# look_back = 1\n",
        "trainX.shape, trainY.shape, testX.shape, testY.shape, trainX[1].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTI5leckaudH"
      },
      "source": [
        "# Many to One"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "LbD1Ju94ZZwx"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesModel(nn.Module):\n",
        "    def __init__(self, look_back, hidden_size=4, num_layers=1): # hiddn_size = 4，output會變4個node， 1層lstm, batch_first = True -> input (N sequence length, L look_back, H)\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.LSTM(2, self.hidden_size, num_layers=self.num_layers, batch_first=True) # nn.LSTM(input_size input-dim, hidden_size hidden-dim, num_layers, batch_first)\n",
        "        self.fc = nn.Linear(self.hidden_size, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('x.shape',x.shape)\n",
        "        # rnn_out, h_out = self.rnn(x)\n",
        "        # 初始化\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, (h_out, _) = self.rnn(x, (h_0, c_0))\n",
        "\n",
        "        print('out: ',out.shape)\n",
        "        print('out value: ',out)\n",
        "        print('out-1: ',out[-1].shape)\n",
        "        print('out-1 value: ',out[-1])\n",
        "        print('h_out: ',h_out.shape)\n",
        "        print('h_out value: ',h_out)\n",
        "        print('h_out[-1]: ',h_out[-1].shape)\n",
        "        print('h_out[-1][-1] value: ',h_out[-1,-1])\n",
        "        # output 的最後一層就是ht\n",
        "\n",
        "        # 取最后一层的 h，并转成二维\n",
        "        h_out = h_out[-1].view(-1, self.hidden_size)\n",
        "        print('h_out-1: ',h_out.shape)\n",
        "\n",
        "        return self.fc(h_out)\n",
        "\n",
        "model = TimeSeriesModel(look_back, hidden_size=4, num_layers=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGKCPfADqGBg",
        "outputId": "11784ef6-c15e-476b-ae32-4484f81fd21e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.5574]],\n",
              "\n",
              "        [[0.0048, 0.8619]],\n",
              "\n",
              "        [[0.0108, 0.7472]],\n",
              "\n",
              "        [[0.0168, 0.8014]],\n",
              "\n",
              "        [[0.0216, 0.8510]],\n",
              "\n",
              "        [[0.0276, 0.0620]],\n",
              "\n",
              "        [[0.0337, 0.9363]],\n",
              "\n",
              "        [[0.0397, 0.1517]],\n",
              "\n",
              "        [[0.0469, 0.9814]],\n",
              "\n",
              "        [[0.0529, 0.7808]],\n",
              "\n",
              "        [[0.0601, 0.6459]],\n",
              "\n",
              "        [[0.0661, 0.6639]],\n",
              "\n",
              "        [[0.0733, 0.7386]]])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLqSsBfEZZur",
        "outputId": "7c2e2ba9-f4ae-49f5-bcc1-c19170bc8f89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([13, 1, 2])\n",
            "out:  torch.Size([13, 1, 4])\n",
            "out value:  tensor([[[-0.0745,  0.0444,  0.0459,  0.0604]],\n",
            "\n",
            "        [[-0.0916,  0.0744,  0.0586,  0.0729]],\n",
            "\n",
            "        [[-0.0864,  0.0624,  0.0533,  0.0682]],\n",
            "\n",
            "        [[-0.0897,  0.0677,  0.0553,  0.0700]],\n",
            "\n",
            "        [[-0.0925,  0.0726,  0.0573,  0.0716]],\n",
            "\n",
            "        [[-0.0389,  0.0006,  0.0254,  0.0299]],\n",
            "\n",
            "        [[-0.0973,  0.0810,  0.0604,  0.0740]],\n",
            "\n",
            "        [[-0.0477,  0.0068,  0.0281,  0.0350]],\n",
            "\n",
            "        [[-0.1003,  0.0853,  0.0618,  0.0748]],\n",
            "\n",
            "        [[-0.0916,  0.0639,  0.0526,  0.0671]],\n",
            "\n",
            "        [[-0.0848,  0.0499,  0.0464,  0.0609]],\n",
            "\n",
            "        [[-0.0864,  0.0514,  0.0469,  0.0613]],\n",
            "\n",
            "        [[-0.0911,  0.0586,  0.0497,  0.0642]]], grad_fn=<TransposeBackward0>)\n",
            "out-1:  torch.Size([1, 4])\n",
            "out-1 value:  tensor([[-0.0911,  0.0586,  0.0497,  0.0642]], grad_fn=<SelectBackward0>)\n",
            "h_out:  torch.Size([1, 13, 4])\n",
            "h_out value:  tensor([[[-0.0745,  0.0444,  0.0459,  0.0604],\n",
            "         [-0.0916,  0.0744,  0.0586,  0.0729],\n",
            "         [-0.0864,  0.0624,  0.0533,  0.0682],\n",
            "         [-0.0897,  0.0677,  0.0553,  0.0700],\n",
            "         [-0.0925,  0.0726,  0.0573,  0.0716],\n",
            "         [-0.0389,  0.0006,  0.0254,  0.0299],\n",
            "         [-0.0973,  0.0810,  0.0604,  0.0740],\n",
            "         [-0.0477,  0.0068,  0.0281,  0.0350],\n",
            "         [-0.1003,  0.0853,  0.0618,  0.0748],\n",
            "         [-0.0916,  0.0639,  0.0526,  0.0671],\n",
            "         [-0.0848,  0.0499,  0.0464,  0.0609],\n",
            "         [-0.0864,  0.0514,  0.0469,  0.0613],\n",
            "         [-0.0911,  0.0586,  0.0497,  0.0642]]], grad_fn=<StackBackward0>)\n",
            "h_out[-1]:  torch.Size([13, 4])\n",
            "h_out[-1][-1] value:  tensor([-0.0911,  0.0586,  0.0497,  0.0642], grad_fn=<SelectBackward0>)\n",
            "h_out-1:  torch.Size([13, 4])\n",
            "torch.Size([13, 1])\n",
            "Epoch: 0, loss: 0.51125\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "def train(trainX, trainY):\n",
        "    criterion = torch.nn.MSELoss()  # MSE\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(trainX) #model是上面定義的LSTM架構\n",
        "\n",
        "        if epoch <= 0: print(outputs.shape)\n",
        "        loss = criterion(outputs, trainY)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch: {epoch}, loss: {loss.item():.5f}\")\n",
        "\n",
        "train(trainX, trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0New6FLRZZsm",
        "outputId": "715ad53a-025f-4fe8-8524-adef59b62768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([13, 1, 2])\n",
            "out:  torch.Size([13, 1, 4])\n",
            "out value:  tensor([[[-0.0809,  0.0505,  0.0536,  0.0546]],\n",
            "\n",
            "        [[-0.0985,  0.0821,  0.0678,  0.0666]],\n",
            "\n",
            "        [[-0.0932,  0.0696,  0.0620,  0.0620]],\n",
            "\n",
            "        [[-0.0965,  0.0752,  0.0643,  0.0637]],\n",
            "\n",
            "        [[-0.0994,  0.0804,  0.0665,  0.0653]],\n",
            "\n",
            "        [[-0.0442,  0.0043,  0.0310,  0.0252]],\n",
            "\n",
            "        [[-0.1044,  0.0893,  0.0701,  0.0675]],\n",
            "\n",
            "        [[-0.0533,  0.0109,  0.0340,  0.0300]],\n",
            "\n",
            "        [[-0.1075,  0.0939,  0.0717,  0.0683]],\n",
            "\n",
            "        [[-0.0986,  0.0715,  0.0616,  0.0608]],\n",
            "\n",
            "        [[-0.0917,  0.0568,  0.0548,  0.0548]],\n",
            "\n",
            "        [[-0.0933,  0.0584,  0.0553,  0.0552]],\n",
            "\n",
            "        [[-0.0981,  0.0661,  0.0585,  0.0580]]], grad_fn=<TransposeBackward0>)\n",
            "out-1:  torch.Size([1, 4])\n",
            "out-1 value:  tensor([[-0.0981,  0.0661,  0.0585,  0.0580]], grad_fn=<SelectBackward0>)\n",
            "h_out:  torch.Size([1, 13, 4])\n",
            "h_out value:  tensor([[[-0.0809,  0.0505,  0.0536,  0.0546],\n",
            "         [-0.0985,  0.0821,  0.0678,  0.0666],\n",
            "         [-0.0932,  0.0696,  0.0620,  0.0620],\n",
            "         [-0.0965,  0.0752,  0.0643,  0.0637],\n",
            "         [-0.0994,  0.0804,  0.0665,  0.0653],\n",
            "         [-0.0442,  0.0043,  0.0310,  0.0252],\n",
            "         [-0.1044,  0.0893,  0.0701,  0.0675],\n",
            "         [-0.0533,  0.0109,  0.0340,  0.0300],\n",
            "         [-0.1075,  0.0939,  0.0717,  0.0683],\n",
            "         [-0.0986,  0.0715,  0.0616,  0.0608],\n",
            "         [-0.0917,  0.0568,  0.0548,  0.0548],\n",
            "         [-0.0933,  0.0584,  0.0553,  0.0552],\n",
            "         [-0.0981,  0.0661,  0.0585,  0.0580]]], grad_fn=<StackBackward0>)\n",
            "h_out[-1]:  torch.Size([13, 4])\n",
            "h_out[-1][-1] value:  tensor([-0.0981,  0.0661,  0.0585,  0.0580], grad_fn=<SelectBackward0>)\n",
            "h_out-1:  torch.Size([13, 4])\n",
            "x.shape torch.Size([134, 1, 2])\n",
            "out:  torch.Size([134, 1, 4])\n",
            "out value:  tensor([[[-6.1867e-02,  1.0958e-02,  3.2993e-02,  2.8595e-02]],\n",
            "\n",
            "        [[-8.2066e-02,  3.3342e-02,  4.3125e-02,  4.2041e-02]],\n",
            "\n",
            "        [[-1.0167e-01,  6.4223e-02,  5.6534e-02,  5.5606e-02]],\n",
            "\n",
            "        [[-1.0453e-01,  6.8210e-02,  5.8017e-02,  5.6735e-02]],\n",
            "\n",
            "        [[-1.0482e-01,  6.6539e-02,  5.7001e-02,  5.5725e-02]],\n",
            "\n",
            "        [[-5.6290e-02, -7.9603e-04,  2.6603e-02,  1.8840e-02]],\n",
            "\n",
            "        [[-7.7520e-02,  1.9587e-02,  3.5917e-02,  3.2807e-02]],\n",
            "\n",
            "        [[-5.5416e-02, -4.1945e-03,  2.4670e-02,  1.5793e-02]],\n",
            "\n",
            "        [[-1.0003e-01,  4.8988e-02,  4.8396e-02,  4.7279e-02]],\n",
            "\n",
            "        [[-8.8962e-02,  2.9437e-02,  3.9673e-02,  3.7556e-02]],\n",
            "\n",
            "        [[-1.1811e-01,  8.4574e-02,  6.3002e-02,  5.9485e-02]],\n",
            "\n",
            "        [[-9.2277e-02,  3.0667e-02,  3.9779e-02,  3.7622e-02]],\n",
            "\n",
            "        [[-9.8550e-02,  3.8645e-02,  4.3005e-02,  4.1293e-02]],\n",
            "\n",
            "        [[-8.1405e-02,  1.2973e-02,  3.1614e-02,  2.7029e-02]],\n",
            "\n",
            "        [[-7.0165e-02, -5.2495e-04,  2.5349e-02,  1.7677e-02]],\n",
            "\n",
            "        [[-5.9497e-02, -1.1606e-02,  1.9993e-02,  8.7426e-03]],\n",
            "\n",
            "        [[-8.0081e-02,  6.5457e-03,  2.8199e-02,  2.2260e-02]],\n",
            "\n",
            "        [[-1.2453e-01,  8.3285e-02,  6.0299e-02,  5.6403e-02]],\n",
            "\n",
            "        [[-1.1374e-01,  5.3618e-02,  4.7759e-02,  4.5760e-02]],\n",
            "\n",
            "        [[-1.1888e-01,  6.2229e-02,  5.0984e-02,  4.8620e-02]],\n",
            "\n",
            "        [[-6.1424e-02, -1.7469e-02,  1.6499e-02,  3.3729e-03]],\n",
            "\n",
            "        [[-8.4520e-02,  2.4411e-03,  2.5415e-02,  1.8553e-02]],\n",
            "\n",
            "        [[-1.2092e-01,  5.7981e-02,  4.8284e-02,  4.5850e-02]],\n",
            "\n",
            "        [[-1.2537e-01,  6.5882e-02,  5.1149e-02,  4.8280e-02]],\n",
            "\n",
            "        [[-1.2452e-01,  6.0465e-02,  4.8639e-02,  4.5969e-02]],\n",
            "\n",
            "        [[-8.1331e-02, -8.8448e-03,  1.9635e-02,  9.9983e-03]],\n",
            "\n",
            "        [[-1.1697e-01,  3.7979e-02,  3.8998e-02,  3.6292e-02]],\n",
            "\n",
            "        [[-1.1822e-01,  3.7934e-02,  3.8724e-02,  3.5972e-02]],\n",
            "\n",
            "        [[-1.3362e-01,  7.2097e-02,  5.1960e-02,  4.8360e-02]],\n",
            "\n",
            "        [[-1.0742e-01,  1.4648e-02,  2.8810e-02,  2.4111e-02]],\n",
            "\n",
            "        [[-7.3854e-02, -2.4097e-02,  1.1987e-02, -2.4202e-03]],\n",
            "\n",
            "        [[-8.2979e-02, -1.7792e-02,  1.4702e-02,  2.7824e-03]],\n",
            "\n",
            "        [[-1.0067e-01, -6.6692e-04,  2.1886e-02,  1.4655e-02]],\n",
            "\n",
            "        [[-8.1367e-02, -2.2576e-02,  1.2286e-02, -1.0774e-03]],\n",
            "\n",
            "        [[-1.3418e-01,  5.4872e-02,  4.3483e-02,  4.0494e-02]],\n",
            "\n",
            "        [[-1.3358e-01,  5.0232e-02,  4.1409e-02,  3.8473e-02]],\n",
            "\n",
            "        [[-1.2528e-01,  2.9182e-02,  3.3035e-02,  2.9616e-02]],\n",
            "\n",
            "        [[-1.3326e-01,  4.3800e-02,  3.8419e-02,  3.5446e-02]],\n",
            "\n",
            "        [[-8.0814e-02, -3.0808e-02,  7.9737e-03, -7.8553e-03]],\n",
            "\n",
            "        [[-1.4644e-01,  7.6244e-02,  5.0184e-02,  4.5850e-02]],\n",
            "\n",
            "        [[-1.0680e-01, -8.3917e-03,  1.7292e-02,  8.8401e-03]],\n",
            "\n",
            "        [[-1.4773e-01,  7.3524e-02,  4.8558e-02,  4.4397e-02]],\n",
            "\n",
            "        [[-1.4740e-01,  6.8379e-02,  4.6309e-02,  4.2487e-02]],\n",
            "\n",
            "        [[-1.1145e-01, -8.7911e-03,  1.6585e-02,  8.2947e-03]],\n",
            "\n",
            "        [[-1.3454e-01,  2.6728e-02,  3.0137e-02,  2.6552e-02]],\n",
            "\n",
            "        [[-1.2560e-01,  6.9330e-03,  2.2342e-02,  1.6929e-02]],\n",
            "\n",
            "        [[-1.4791e-01,  5.4484e-02,  3.9894e-02,  3.6650e-02]],\n",
            "\n",
            "        [[-1.3039e-01,  1.0129e-02,  2.3122e-02,  1.8191e-02]],\n",
            "\n",
            "        [[-1.0054e-01, -3.0872e-02,  6.6693e-03, -7.1869e-03]],\n",
            "\n",
            "        [[-1.0899e-01, -2.4215e-02,  9.2909e-03, -2.2205e-03]],\n",
            "\n",
            "        [[-1.5566e-01,  6.5714e-02,  4.2799e-02,  3.9053e-02]],\n",
            "\n",
            "        [[-1.1647e-01, -1.9736e-02,  1.0771e-02,  7.9252e-04]],\n",
            "\n",
            "        [[-1.3084e-01, -1.8766e-03,  1.7495e-02,  1.1243e-02]],\n",
            "\n",
            "        [[-1.5888e-01,  6.5284e-02,  4.1708e-02,  3.7995e-02]],\n",
            "\n",
            "        [[-9.8572e-02, -4.3403e-02,  5.6867e-04, -1.6807e-02]],\n",
            "\n",
            "        [[-1.2849e-01, -1.2822e-02,  1.2743e-02,  4.8434e-03]],\n",
            "\n",
            "        [[-1.1562e-01, -3.0877e-02,  5.5385e-03, -6.7649e-03]],\n",
            "\n",
            "        [[-1.5126e-01,  2.5756e-02,  2.6474e-02,  2.3138e-02]],\n",
            "\n",
            "        [[-1.2488e-01, -2.4042e-02,  7.9352e-03, -2.1148e-03]],\n",
            "\n",
            "        [[-1.5504e-01,  2.9868e-02,  2.7475e-02,  2.4360e-02]],\n",
            "\n",
            "        [[-1.0335e-01, -4.9249e-02, -2.5385e-03, -2.0847e-02]],\n",
            "\n",
            "        [[-1.4388e-01, -1.3294e-03,  1.5912e-02,  1.0456e-02]],\n",
            "\n",
            "        [[-1.6264e-01,  4.3604e-02,  3.1564e-02,  2.8689e-02]],\n",
            "\n",
            "        [[-1.2332e-01, -3.5431e-02,  2.7920e-03, -9.6094e-03]],\n",
            "\n",
            "        [[-1.5037e-01,  3.9519e-03,  1.7218e-02,  1.2621e-02]],\n",
            "\n",
            "        [[-1.3902e-01, -1.8643e-02,  8.8962e-03,  9.9161e-04]],\n",
            "\n",
            "        [[-1.3379e-01, -2.8257e-02,  5.1524e-03, -4.7523e-03]],\n",
            "\n",
            "        [[-1.6979e-01,  5.2130e-02,  3.3252e-02,  3.0365e-02]],\n",
            "\n",
            "        [[-1.0987e-01, -5.6172e-02, -6.1658e-03, -2.5340e-02]],\n",
            "\n",
            "        [[-1.6873e-01,  4.0796e-02,  2.8939e-02,  2.6310e-02]],\n",
            "\n",
            "        [[-1.1535e-01, -5.4458e-02, -5.5964e-03, -2.3446e-02]],\n",
            "\n",
            "        [[-1.6883e-01,  3.4518e-02,  2.6379e-02,  2.3812e-02]],\n",
            "\n",
            "        [[-1.3106e-01, -4.2128e-02, -8.6451e-04, -1.3653e-02]],\n",
            "\n",
            "        [[-1.6685e-01,  2.1719e-02,  2.1636e-02,  1.8847e-02]],\n",
            "\n",
            "        [[-1.6436e-01,  1.1617e-02,  1.8017e-02,  1.4743e-02]],\n",
            "\n",
            "        [[-1.6234e-01,  3.6869e-03,  1.5132e-02,  1.1301e-02]],\n",
            "\n",
            "        [[-1.4906e-01, -2.4761e-02,  5.0839e-03, -2.6835e-03]],\n",
            "\n",
            "        [[-1.5856e-01, -9.4508e-03,  1.0307e-02,  5.1753e-03]],\n",
            "\n",
            "        [[-1.7120e-01,  2.1287e-02,  2.0561e-02,  1.8018e-02]],\n",
            "\n",
            "        [[-1.5358e-01, -2.3034e-02,  5.2870e-03, -1.7778e-03]],\n",
            "\n",
            "        [[-1.4619e-01, -3.6276e-02,  4.3744e-04, -9.3543e-03]],\n",
            "\n",
            "        [[-1.7175e-01,  1.4771e-02,  1.7865e-02,  1.5201e-02]],\n",
            "\n",
            "        [[-1.5585e-01, -2.4407e-02,  4.4377e-03, -2.5503e-03]],\n",
            "\n",
            "        [[-1.6815e-01, -2.2436e-04,  1.2556e-02,  8.9417e-03]],\n",
            "\n",
            "        [[-1.8029e-01,  3.8479e-02,  2.5185e-02,  2.3176e-02]],\n",
            "\n",
            "        [[-1.3818e-01, -5.3258e-02, -6.3290e-03, -2.0332e-02]],\n",
            "\n",
            "        [[-1.7994e-01,  3.0595e-02,  2.2251e-02,  2.0322e-02]],\n",
            "\n",
            "        [[-1.4079e-01, -5.2893e-02, -6.3422e-03, -1.9864e-02]],\n",
            "\n",
            "        [[-1.3536e-01, -5.9671e-02, -9.0004e-03, -2.4816e-02]],\n",
            "\n",
            "        [[-1.4089e-01, -5.5303e-02, -7.4036e-03, -2.1389e-02]],\n",
            "\n",
            "        [[-1.8515e-01,  4.3059e-02,  2.5669e-02,  2.3854e-02]],\n",
            "\n",
            "        [[-1.4906e-01, -4.7942e-02, -4.8170e-03, -1.6161e-02]],\n",
            "\n",
            "        [[-1.8578e-01,  4.0418e-02,  2.4517e-02,  2.2821e-02]],\n",
            "\n",
            "        [[-1.6840e-01, -1.7875e-02,  5.4586e-03,  5.3324e-04]],\n",
            "\n",
            "        [[-1.5336e-01, -4.5614e-02, -4.1945e-03, -1.4514e-02]],\n",
            "\n",
            "        [[-1.2956e-01, -7.1851e-02, -1.4200e-02, -3.3919e-02]],\n",
            "\n",
            "        [[-1.8586e-01,  3.0959e-02,  2.0972e-02,  1.9462e-02]],\n",
            "\n",
            "        [[-1.5742e-01, -4.3362e-02, -3.6238e-03, -1.3004e-02]],\n",
            "\n",
            "        [[-1.6961e-01, -2.2709e-02,  3.3638e-03, -1.8773e-03]],\n",
            "\n",
            "        [[-1.6353e-01, -3.5601e-02, -1.0651e-03, -8.5168e-03]],\n",
            "\n",
            "        [[-1.8290e-01,  1.0306e-02,  1.3897e-02,  1.2002e-02]],\n",
            "\n",
            "        [[-1.7156e-01, -2.2651e-02,  3.1185e-03, -1.8865e-03]],\n",
            "\n",
            "        [[-1.7260e-01, -2.1614e-02,  3.3812e-03, -1.4046e-03]],\n",
            "\n",
            "        [[-1.6481e-01, -3.8138e-02, -2.2349e-03, -9.8400e-03]],\n",
            "\n",
            "        [[-1.4345e-01, -6.6939e-02, -1.2624e-02, -2.8591e-02]],\n",
            "\n",
            "        [[-1.8670e-01,  1.5682e-02,  1.5104e-02,  1.3653e-02]],\n",
            "\n",
            "        [[-1.3298e-01, -7.7571e-02, -1.6887e-02, -3.7351e-02]],\n",
            "\n",
            "        [[-1.6258e-01, -4.5705e-02, -5.0810e-03, -1.4053e-02]],\n",
            "\n",
            "        [[-1.5136e-01, -6.1633e-02, -1.0807e-02, -2.4282e-02]],\n",
            "\n",
            "        [[-1.8659e-01,  9.1313e-03,  1.2700e-02,  1.1122e-02]],\n",
            "\n",
            "        [[-1.3970e-01, -7.4580e-02, -1.5793e-02, -3.4185e-02]],\n",
            "\n",
            "        [[-1.4825e-01, -6.7032e-02, -1.2921e-02, -2.8025e-02]],\n",
            "\n",
            "        [[-1.7737e-01, -2.2355e-02,  2.4076e-03, -1.8648e-03]],\n",
            "\n",
            "        [[-1.6300e-01, -5.0193e-02, -6.9515e-03, -1.6528e-02]],\n",
            "\n",
            "        [[-1.3560e-01, -8.0130e-02, -1.8107e-02, -3.8669e-02]],\n",
            "\n",
            "        [[-1.5012e-01, -6.7597e-02, -1.3267e-02, -2.8140e-02]],\n",
            "\n",
            "        [[-1.4824e-01, -7.0357e-02, -1.4346e-02, -3.0142e-02]],\n",
            "\n",
            "        [[-1.8958e-01,  9.0092e-03,  1.2031e-02,  1.0746e-02]],\n",
            "\n",
            "        [[-1.4983e-01, -6.9857e-02, -1.4214e-02, -2.9604e-02]],\n",
            "\n",
            "        [[-1.9357e-01,  2.3859e-02,  1.6510e-02,  1.5720e-02]],\n",
            "\n",
            "        [[-1.6593e-01, -5.0904e-02, -7.5081e-03, -1.6725e-02]],\n",
            "\n",
            "        [[-1.9431e-01,  2.4581e-02,  1.6590e-02,  1.5865e-02]],\n",
            "\n",
            "        [[-1.4809e-01, -7.3509e-02, -1.5689e-02, -3.2188e-02]],\n",
            "\n",
            "        [[-1.9418e-01,  2.1725e-02,  1.5600e-02,  1.4878e-02]],\n",
            "\n",
            "        [[-1.9530e-01,  2.5891e-02,  1.6814e-02,  1.6172e-02]],\n",
            "\n",
            "        [[-1.6284e-01, -5.8406e-02, -1.0290e-02, -2.1201e-02]],\n",
            "\n",
            "        [[-1.8016e-01, -2.7826e-02, -9.1132e-05, -4.4825e-03]],\n",
            "\n",
            "        [[-1.9325e-01,  1.2535e-02,  1.2518e-02,  1.1664e-02]],\n",
            "\n",
            "        [[-1.5654e-01, -6.7801e-02, -1.3729e-02, -2.7449e-02]],\n",
            "\n",
            "        [[-1.6697e-01, -5.4517e-02, -9.0582e-03, -1.8651e-02]],\n",
            "\n",
            "        [[-1.6198e-01, -6.1805e-02, -1.1615e-02, -2.3251e-02]],\n",
            "\n",
            "        [[-1.9165e-01,  2.1991e-03,  9.1242e-03,  7.8908e-03]],\n",
            "\n",
            "        [[-1.8326e-01, -2.4383e-02,  7.6692e-04, -2.9199e-03]],\n",
            "\n",
            "        [[-1.8884e-01, -8.8483e-03,  5.6298e-03,  3.6438e-03]]],\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "out-1:  torch.Size([1, 4])\n",
            "out-1 value:  tensor([[-0.1888, -0.0088,  0.0056,  0.0036]], grad_fn=<SelectBackward0>)\n",
            "h_out:  torch.Size([1, 134, 4])\n",
            "h_out value:  tensor([[[-6.1867e-02,  1.0958e-02,  3.2993e-02,  2.8595e-02],\n",
            "         [-8.2066e-02,  3.3342e-02,  4.3125e-02,  4.2041e-02],\n",
            "         [-1.0167e-01,  6.4223e-02,  5.6534e-02,  5.5606e-02],\n",
            "         [-1.0453e-01,  6.8210e-02,  5.8017e-02,  5.6735e-02],\n",
            "         [-1.0482e-01,  6.6539e-02,  5.7001e-02,  5.5725e-02],\n",
            "         [-5.6290e-02, -7.9603e-04,  2.6603e-02,  1.8840e-02],\n",
            "         [-7.7520e-02,  1.9587e-02,  3.5917e-02,  3.2807e-02],\n",
            "         [-5.5416e-02, -4.1945e-03,  2.4670e-02,  1.5793e-02],\n",
            "         [-1.0003e-01,  4.8988e-02,  4.8396e-02,  4.7279e-02],\n",
            "         [-8.8962e-02,  2.9437e-02,  3.9673e-02,  3.7556e-02],\n",
            "         [-1.1811e-01,  8.4574e-02,  6.3002e-02,  5.9485e-02],\n",
            "         [-9.2277e-02,  3.0667e-02,  3.9779e-02,  3.7622e-02],\n",
            "         [-9.8550e-02,  3.8645e-02,  4.3005e-02,  4.1293e-02],\n",
            "         [-8.1405e-02,  1.2973e-02,  3.1614e-02,  2.7029e-02],\n",
            "         [-7.0165e-02, -5.2495e-04,  2.5349e-02,  1.7677e-02],\n",
            "         [-5.9497e-02, -1.1606e-02,  1.9993e-02,  8.7426e-03],\n",
            "         [-8.0081e-02,  6.5457e-03,  2.8199e-02,  2.2260e-02],\n",
            "         [-1.2453e-01,  8.3285e-02,  6.0299e-02,  5.6403e-02],\n",
            "         [-1.1374e-01,  5.3618e-02,  4.7759e-02,  4.5760e-02],\n",
            "         [-1.1888e-01,  6.2229e-02,  5.0984e-02,  4.8620e-02],\n",
            "         [-6.1424e-02, -1.7469e-02,  1.6499e-02,  3.3729e-03],\n",
            "         [-8.4520e-02,  2.4411e-03,  2.5415e-02,  1.8553e-02],\n",
            "         [-1.2092e-01,  5.7981e-02,  4.8284e-02,  4.5850e-02],\n",
            "         [-1.2537e-01,  6.5882e-02,  5.1149e-02,  4.8280e-02],\n",
            "         [-1.2452e-01,  6.0465e-02,  4.8639e-02,  4.5969e-02],\n",
            "         [-8.1331e-02, -8.8448e-03,  1.9635e-02,  9.9983e-03],\n",
            "         [-1.1697e-01,  3.7979e-02,  3.8998e-02,  3.6292e-02],\n",
            "         [-1.1822e-01,  3.7934e-02,  3.8724e-02,  3.5972e-02],\n",
            "         [-1.3362e-01,  7.2097e-02,  5.1960e-02,  4.8360e-02],\n",
            "         [-1.0742e-01,  1.4648e-02,  2.8810e-02,  2.4111e-02],\n",
            "         [-7.3854e-02, -2.4097e-02,  1.1987e-02, -2.4202e-03],\n",
            "         [-8.2979e-02, -1.7792e-02,  1.4702e-02,  2.7824e-03],\n",
            "         [-1.0067e-01, -6.6692e-04,  2.1886e-02,  1.4655e-02],\n",
            "         [-8.1367e-02, -2.2576e-02,  1.2286e-02, -1.0774e-03],\n",
            "         [-1.3418e-01,  5.4872e-02,  4.3483e-02,  4.0494e-02],\n",
            "         [-1.3358e-01,  5.0232e-02,  4.1409e-02,  3.8473e-02],\n",
            "         [-1.2528e-01,  2.9182e-02,  3.3035e-02,  2.9616e-02],\n",
            "         [-1.3326e-01,  4.3800e-02,  3.8419e-02,  3.5446e-02],\n",
            "         [-8.0814e-02, -3.0808e-02,  7.9737e-03, -7.8553e-03],\n",
            "         [-1.4644e-01,  7.6244e-02,  5.0184e-02,  4.5850e-02],\n",
            "         [-1.0680e-01, -8.3917e-03,  1.7292e-02,  8.8401e-03],\n",
            "         [-1.4773e-01,  7.3524e-02,  4.8558e-02,  4.4397e-02],\n",
            "         [-1.4740e-01,  6.8379e-02,  4.6309e-02,  4.2487e-02],\n",
            "         [-1.1145e-01, -8.7911e-03,  1.6585e-02,  8.2947e-03],\n",
            "         [-1.3454e-01,  2.6728e-02,  3.0137e-02,  2.6552e-02],\n",
            "         [-1.2560e-01,  6.9330e-03,  2.2342e-02,  1.6929e-02],\n",
            "         [-1.4791e-01,  5.4484e-02,  3.9894e-02,  3.6650e-02],\n",
            "         [-1.3039e-01,  1.0129e-02,  2.3122e-02,  1.8191e-02],\n",
            "         [-1.0054e-01, -3.0872e-02,  6.6693e-03, -7.1869e-03],\n",
            "         [-1.0899e-01, -2.4215e-02,  9.2909e-03, -2.2205e-03],\n",
            "         [-1.5566e-01,  6.5714e-02,  4.2799e-02,  3.9053e-02],\n",
            "         [-1.1647e-01, -1.9736e-02,  1.0771e-02,  7.9252e-04],\n",
            "         [-1.3084e-01, -1.8766e-03,  1.7495e-02,  1.1243e-02],\n",
            "         [-1.5888e-01,  6.5284e-02,  4.1708e-02,  3.7995e-02],\n",
            "         [-9.8572e-02, -4.3403e-02,  5.6867e-04, -1.6807e-02],\n",
            "         [-1.2849e-01, -1.2822e-02,  1.2743e-02,  4.8434e-03],\n",
            "         [-1.1562e-01, -3.0877e-02,  5.5385e-03, -6.7649e-03],\n",
            "         [-1.5126e-01,  2.5756e-02,  2.6474e-02,  2.3138e-02],\n",
            "         [-1.2488e-01, -2.4042e-02,  7.9352e-03, -2.1148e-03],\n",
            "         [-1.5504e-01,  2.9868e-02,  2.7475e-02,  2.4360e-02],\n",
            "         [-1.0335e-01, -4.9249e-02, -2.5385e-03, -2.0847e-02],\n",
            "         [-1.4388e-01, -1.3294e-03,  1.5912e-02,  1.0456e-02],\n",
            "         [-1.6264e-01,  4.3604e-02,  3.1564e-02,  2.8689e-02],\n",
            "         [-1.2332e-01, -3.5431e-02,  2.7920e-03, -9.6094e-03],\n",
            "         [-1.5037e-01,  3.9519e-03,  1.7218e-02,  1.2621e-02],\n",
            "         [-1.3902e-01, -1.8643e-02,  8.8962e-03,  9.9161e-04],\n",
            "         [-1.3379e-01, -2.8257e-02,  5.1524e-03, -4.7523e-03],\n",
            "         [-1.6979e-01,  5.2130e-02,  3.3252e-02,  3.0365e-02],\n",
            "         [-1.0987e-01, -5.6172e-02, -6.1658e-03, -2.5340e-02],\n",
            "         [-1.6873e-01,  4.0796e-02,  2.8939e-02,  2.6310e-02],\n",
            "         [-1.1535e-01, -5.4458e-02, -5.5964e-03, -2.3446e-02],\n",
            "         [-1.6883e-01,  3.4518e-02,  2.6379e-02,  2.3812e-02],\n",
            "         [-1.3106e-01, -4.2128e-02, -8.6451e-04, -1.3653e-02],\n",
            "         [-1.6685e-01,  2.1719e-02,  2.1636e-02,  1.8847e-02],\n",
            "         [-1.6436e-01,  1.1617e-02,  1.8017e-02,  1.4743e-02],\n",
            "         [-1.6234e-01,  3.6869e-03,  1.5132e-02,  1.1301e-02],\n",
            "         [-1.4906e-01, -2.4761e-02,  5.0839e-03, -2.6835e-03],\n",
            "         [-1.5856e-01, -9.4508e-03,  1.0307e-02,  5.1753e-03],\n",
            "         [-1.7120e-01,  2.1287e-02,  2.0561e-02,  1.8018e-02],\n",
            "         [-1.5358e-01, -2.3034e-02,  5.2870e-03, -1.7778e-03],\n",
            "         [-1.4619e-01, -3.6276e-02,  4.3744e-04, -9.3543e-03],\n",
            "         [-1.7175e-01,  1.4771e-02,  1.7865e-02,  1.5201e-02],\n",
            "         [-1.5585e-01, -2.4407e-02,  4.4377e-03, -2.5503e-03],\n",
            "         [-1.6815e-01, -2.2436e-04,  1.2556e-02,  8.9417e-03],\n",
            "         [-1.8029e-01,  3.8479e-02,  2.5185e-02,  2.3176e-02],\n",
            "         [-1.3818e-01, -5.3258e-02, -6.3290e-03, -2.0332e-02],\n",
            "         [-1.7994e-01,  3.0595e-02,  2.2251e-02,  2.0322e-02],\n",
            "         [-1.4079e-01, -5.2893e-02, -6.3422e-03, -1.9864e-02],\n",
            "         [-1.3536e-01, -5.9671e-02, -9.0004e-03, -2.4816e-02],\n",
            "         [-1.4089e-01, -5.5303e-02, -7.4036e-03, -2.1389e-02],\n",
            "         [-1.8515e-01,  4.3059e-02,  2.5669e-02,  2.3854e-02],\n",
            "         [-1.4906e-01, -4.7942e-02, -4.8170e-03, -1.6161e-02],\n",
            "         [-1.8578e-01,  4.0418e-02,  2.4517e-02,  2.2821e-02],\n",
            "         [-1.6840e-01, -1.7875e-02,  5.4586e-03,  5.3324e-04],\n",
            "         [-1.5336e-01, -4.5614e-02, -4.1945e-03, -1.4514e-02],\n",
            "         [-1.2956e-01, -7.1851e-02, -1.4200e-02, -3.3919e-02],\n",
            "         [-1.8586e-01,  3.0959e-02,  2.0972e-02,  1.9462e-02],\n",
            "         [-1.5742e-01, -4.3362e-02, -3.6238e-03, -1.3004e-02],\n",
            "         [-1.6961e-01, -2.2709e-02,  3.3638e-03, -1.8773e-03],\n",
            "         [-1.6353e-01, -3.5601e-02, -1.0651e-03, -8.5168e-03],\n",
            "         [-1.8290e-01,  1.0306e-02,  1.3897e-02,  1.2002e-02],\n",
            "         [-1.7156e-01, -2.2651e-02,  3.1185e-03, -1.8865e-03],\n",
            "         [-1.7260e-01, -2.1614e-02,  3.3812e-03, -1.4046e-03],\n",
            "         [-1.6481e-01, -3.8138e-02, -2.2349e-03, -9.8400e-03],\n",
            "         [-1.4345e-01, -6.6939e-02, -1.2624e-02, -2.8591e-02],\n",
            "         [-1.8670e-01,  1.5682e-02,  1.5104e-02,  1.3653e-02],\n",
            "         [-1.3298e-01, -7.7571e-02, -1.6887e-02, -3.7351e-02],\n",
            "         [-1.6258e-01, -4.5705e-02, -5.0810e-03, -1.4053e-02],\n",
            "         [-1.5136e-01, -6.1633e-02, -1.0807e-02, -2.4282e-02],\n",
            "         [-1.8659e-01,  9.1313e-03,  1.2700e-02,  1.1122e-02],\n",
            "         [-1.3970e-01, -7.4580e-02, -1.5793e-02, -3.4185e-02],\n",
            "         [-1.4825e-01, -6.7032e-02, -1.2921e-02, -2.8025e-02],\n",
            "         [-1.7737e-01, -2.2355e-02,  2.4076e-03, -1.8648e-03],\n",
            "         [-1.6300e-01, -5.0193e-02, -6.9515e-03, -1.6528e-02],\n",
            "         [-1.3560e-01, -8.0130e-02, -1.8107e-02, -3.8669e-02],\n",
            "         [-1.5012e-01, -6.7597e-02, -1.3267e-02, -2.8140e-02],\n",
            "         [-1.4824e-01, -7.0357e-02, -1.4346e-02, -3.0142e-02],\n",
            "         [-1.8958e-01,  9.0092e-03,  1.2031e-02,  1.0746e-02],\n",
            "         [-1.4983e-01, -6.9857e-02, -1.4214e-02, -2.9604e-02],\n",
            "         [-1.9357e-01,  2.3859e-02,  1.6510e-02,  1.5720e-02],\n",
            "         [-1.6593e-01, -5.0904e-02, -7.5081e-03, -1.6725e-02],\n",
            "         [-1.9431e-01,  2.4581e-02,  1.6590e-02,  1.5865e-02],\n",
            "         [-1.4809e-01, -7.3509e-02, -1.5689e-02, -3.2188e-02],\n",
            "         [-1.9418e-01,  2.1725e-02,  1.5600e-02,  1.4878e-02],\n",
            "         [-1.9530e-01,  2.5891e-02,  1.6814e-02,  1.6172e-02],\n",
            "         [-1.6284e-01, -5.8406e-02, -1.0290e-02, -2.1201e-02],\n",
            "         [-1.8016e-01, -2.7826e-02, -9.1132e-05, -4.4825e-03],\n",
            "         [-1.9325e-01,  1.2535e-02,  1.2518e-02,  1.1664e-02],\n",
            "         [-1.5654e-01, -6.7801e-02, -1.3729e-02, -2.7449e-02],\n",
            "         [-1.6697e-01, -5.4517e-02, -9.0582e-03, -1.8651e-02],\n",
            "         [-1.6198e-01, -6.1805e-02, -1.1615e-02, -2.3251e-02],\n",
            "         [-1.9165e-01,  2.1991e-03,  9.1242e-03,  7.8908e-03],\n",
            "         [-1.8326e-01, -2.4383e-02,  7.6692e-04, -2.9199e-03],\n",
            "         [-1.8884e-01, -8.8483e-03,  5.6298e-03,  3.6438e-03]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "h_out[-1]:  torch.Size([134, 4])\n",
            "h_out[-1][-1] value:  tensor([-0.1888, -0.0088,  0.0056,  0.0036], grad_fn=<SelectBackward0>)\n",
            "h_out-1:  torch.Size([134, 4])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(13, 1)"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "trainPredict = model(trainX).detach().numpy()\n",
        "testPredict = model(testX).detach().numpy()\n",
        "trainPredict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-XG7Mnrk4RV",
        "outputId": "f47313be-0cc9-4ee1-a2db-3eaac0508222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([13, 1]), (13, 1))"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainY.shape, trainPredict.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIWzl-Rgax5p"
      },
      "source": [
        "# Many to Many"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "JUWwE8tZZZp_"
      },
      "outputs": [],
      "source": [
        "class TimeSeriesModel(nn.Module):\n",
        "    def __init__(self, look_back, hidden_size=4, num_layers=1): # hiddn_size = 4，output會變4個node， 1層lstm, batch_first = True -> input (N sequence length, L look_back, H)\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.LSTM(2, self.hidden_size, num_layers=self.num_layers, batch_first=True) # nn.LSTM(input_size input-dim, hidden_size hidden-dim, num_layers, batch_first)\n",
        "        self.fc = nn.Linear(self.hidden_size, 1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        print('x.shape',x.shape)\n",
        "        # rnn_out, h_out = self.rnn(x)\n",
        "        # 初始化\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
        "        out, (h_out, _) = self.rnn(x, (h_0, c_0))\n",
        "\n",
        "        print('out: ',out.shape)\n",
        "        print('out value: ',out)\n",
        "        # print('out-1: ',out[-1].shape)\n",
        "        # print('out-1 value: ',out[-1])\n",
        "        # print('h_out: ',h_out.shape)\n",
        "        # print('h_out value: ',h_out)\n",
        "        # print('h_out[-1]: ',h_out[-1].shape)\n",
        "        # print('h_out[-1][-1] value: ',h_out[-1,-1])\n",
        "\n",
        "        return self.fc(out)\n",
        "\n",
        "model = TimeSeriesModel(look_back, hidden_size=4, num_layers=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qc-hoHEjZZmF",
        "outputId": "eeb17e35-6c47-4011-8882-180d0df1ff6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TimeSeriesModel(\n",
              "  (rnn): LSTM(2, 4, batch_first=True)\n",
              "  (fc): Linear(in_features=4, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvjmSHCGZZje",
        "outputId": "15bb21af-a66e-4621-e6a8-c02f89ab06a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([13, 1, 2])\n",
            "tensor([[[0.0000, 0.5574]],\n",
            "\n",
            "        [[0.0048, 0.8619]],\n",
            "\n",
            "        [[0.0108, 0.7472]],\n",
            "\n",
            "        [[0.0168, 0.8014]],\n",
            "\n",
            "        [[0.0216, 0.8510]],\n",
            "\n",
            "        [[0.0276, 0.0620]],\n",
            "\n",
            "        [[0.0337, 0.9363]],\n",
            "\n",
            "        [[0.0397, 0.1517]],\n",
            "\n",
            "        [[0.0469, 0.9814]],\n",
            "\n",
            "        [[0.0529, 0.7808]],\n",
            "\n",
            "        [[0.0601, 0.6459]],\n",
            "\n",
            "        [[0.0661, 0.6639]],\n",
            "\n",
            "        [[0.0733, 0.7386]]])\n"
          ]
        }
      ],
      "source": [
        "print(trainX.shape)\n",
        "print(trainX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUEYKp8LZZdx",
        "outputId": "c5a01633-798e-4210-c76d-35eed32ab9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([13, 1, 2])\n",
            "out:  torch.Size([13, 1, 4])\n",
            "out value:  tensor([[[ 0.0514, -0.0228, -0.0569,  0.0142]],\n",
            "\n",
            "        [[ 0.0608, -0.0204, -0.0677,  0.0203]],\n",
            "\n",
            "        [[ 0.0579, -0.0211, -0.0643,  0.0184]],\n",
            "\n",
            "        [[ 0.0597, -0.0205, -0.0665,  0.0196]],\n",
            "\n",
            "        [[ 0.0613, -0.0200, -0.0683,  0.0207]],\n",
            "\n",
            "        [[ 0.0350, -0.0258, -0.0389,  0.0047]],\n",
            "\n",
            "        [[ 0.0641, -0.0191, -0.0716,  0.0227]],\n",
            "\n",
            "        [[ 0.0393, -0.0248, -0.0436,  0.0071]],\n",
            "\n",
            "        [[ 0.0658, -0.0185, -0.0736,  0.0240]],\n",
            "\n",
            "        [[ 0.0610, -0.0198, -0.0679,  0.0205]],\n",
            "\n",
            "        [[ 0.0575, -0.0205, -0.0639,  0.0181]],\n",
            "\n",
            "        [[ 0.0583, -0.0202, -0.0649,  0.0187]],\n",
            "\n",
            "        [[ 0.0608, -0.0195, -0.0678,  0.0204]]], grad_fn=<TransposeBackward0>)\n",
            "This is outputs shape torch.Size([13, 1, 1])\n",
            "Epoch: 0, loss: 0.50444\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([13, 1])) that is different to the input size (torch.Size([13, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1\n",
        "learning_rate = 0.01\n",
        "\n",
        "\n",
        "def train(trainX, trainY):\n",
        "    criterion = torch.nn.MSELoss()  # MSE\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(trainX) #model是上面定義的LSTM架構\n",
        "\n",
        "        if epoch <= 0: print('This is outputs shape', outputs.shape)\n",
        "        loss = criterion(outputs, trainY)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch: {epoch}, loss: {loss.item():.5f}\")\n",
        "\n",
        "train(trainX, trainY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo7ljh-psSuG",
        "outputId": "b7754316-5860-4874-82bc-88070ffcf2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape torch.Size([13, 1, 2])\n",
            "out:  torch.Size([13, 1, 4])\n",
            "out value:  tensor([[[ 0.0415, -0.0272, -0.0629,  0.0100]],\n",
            "\n",
            "        [[ 0.0501, -0.0250, -0.0744,  0.0155]],\n",
            "\n",
            "        [[ 0.0475, -0.0256, -0.0708,  0.0137]],\n",
            "\n",
            "        [[ 0.0492, -0.0251, -0.0731,  0.0148]],\n",
            "\n",
            "        [[ 0.0507, -0.0247, -0.0750,  0.0158]],\n",
            "\n",
            "        [[ 0.0264, -0.0298, -0.0436,  0.0013]],\n",
            "\n",
            "        [[ 0.0532, -0.0238, -0.0784,  0.0176]],\n",
            "\n",
            "        [[ 0.0304, -0.0289, -0.0486,  0.0034]],\n",
            "\n",
            "        [[ 0.0549, -0.0232, -0.0805,  0.0188]],\n",
            "\n",
            "        [[ 0.0504, -0.0243, -0.0745,  0.0156]],\n",
            "\n",
            "        [[ 0.0472, -0.0250, -0.0702,  0.0135]],\n",
            "\n",
            "        [[ 0.0480, -0.0247, -0.0712,  0.0140]],\n",
            "\n",
            "        [[ 0.0503, -0.0241, -0.0743,  0.0155]]], grad_fn=<TransposeBackward0>)\n",
            "x.shape torch.Size([134, 1, 2])\n",
            "out:  torch.Size([134, 1, 4])\n",
            "out value:  tensor([[[ 0.0352, -0.0270, -0.0546,  0.0060]],\n",
            "\n",
            "        [[ 0.0436, -0.0252, -0.0652,  0.0111]],\n",
            "\n",
            "        [[ 0.0522, -0.0231, -0.0766,  0.0168]],\n",
            "\n",
            "        [[ 0.0535, -0.0226, -0.0783,  0.0178]],\n",
            "\n",
            "        [[ 0.0537, -0.0225, -0.0785,  0.0179]],\n",
            "\n",
            "        [[ 0.0342, -0.0264, -0.0531,  0.0053]],\n",
            "\n",
            "        [[ 0.0425, -0.0247, -0.0636,  0.0103]],\n",
            "\n",
            "        [[ 0.0343, -0.0261, -0.0532,  0.0053]],\n",
            "\n",
            "        [[ 0.0519, -0.0224, -0.0758,  0.0165]],\n",
            "\n",
            "        [[ 0.0475, -0.0233, -0.0699,  0.0135]],\n",
            "\n",
            "        [[ 0.0600, -0.0202, -0.0864,  0.0227]],\n",
            "\n",
            "        [[ 0.0491, -0.0227, -0.0718,  0.0145]],\n",
            "\n",
            "        [[ 0.0517, -0.0220, -0.0752,  0.0163]],\n",
            "\n",
            "        [[ 0.0452, -0.0232, -0.0667,  0.0118]],\n",
            "\n",
            "        [[ 0.0413, -0.0238, -0.0616,  0.0093]],\n",
            "\n",
            "        [[ 0.0377, -0.0242, -0.0571,  0.0071]],\n",
            "\n",
            "        [[ 0.0452, -0.0228, -0.0665,  0.0118]],\n",
            "\n",
            "        [[ 0.0628, -0.0187, -0.0896,  0.0251]],\n",
            "\n",
            "        [[ 0.0583, -0.0197, -0.0835,  0.0212]],\n",
            "\n",
            "        [[ 0.0604, -0.0191, -0.0862,  0.0230]],\n",
            "\n",
            "        [[ 0.0396, -0.0231, -0.0591,  0.0081]],\n",
            "\n",
            "        [[ 0.0478, -0.0215, -0.0693,  0.0134]],\n",
            "\n",
            "        [[ 0.0614, -0.0185, -0.0871,  0.0237]],\n",
            "\n",
            "        [[ 0.0632, -0.0179, -0.0894,  0.0254]],\n",
            "\n",
            "        [[ 0.0629, -0.0179, -0.0889,  0.0250]],\n",
            "\n",
            "        [[ 0.0476, -0.0209, -0.0686,  0.0131]],\n",
            "\n",
            "        [[ 0.0601, -0.0183, -0.0849,  0.0225]],\n",
            "\n",
            "        [[ 0.0606, -0.0180, -0.0855,  0.0230]],\n",
            "\n",
            "        [[ 0.0666, -0.0164, -0.0932,  0.0285]],\n",
            "\n",
            "        [[ 0.0570, -0.0186, -0.0805,  0.0199]],\n",
            "\n",
            "        [[ 0.0463, -0.0203, -0.0665,  0.0120]],\n",
            "\n",
            "        [[ 0.0494, -0.0197, -0.0703,  0.0141]],\n",
            "\n",
            "        [[ 0.0552, -0.0185, -0.0777,  0.0184]],\n",
            "\n",
            "        [[ 0.0493, -0.0194, -0.0699,  0.0140]],\n",
            "\n",
            "        [[ 0.0668, -0.0158, -0.0929,  0.0286]],\n",
            "\n",
            "        [[ 0.0666, -0.0158, -0.0925,  0.0283]],\n",
            "\n",
            "        [[ 0.0638, -0.0164, -0.0886,  0.0255]],\n",
            "\n",
            "        [[ 0.0666, -0.0156, -0.0922,  0.0282]],\n",
            "\n",
            "        [[ 0.0502, -0.0186, -0.0704,  0.0144]],\n",
            "\n",
            "        [[ 0.0714, -0.0141, -0.0982,  0.0334]],\n",
            "\n",
            "        [[ 0.0583, -0.0170, -0.0807,  0.0206]],\n",
            "\n",
            "        [[ 0.0719, -0.0138, -0.0985,  0.0339]],\n",
            "\n",
            "        [[ 0.0717, -0.0138, -0.0982,  0.0337]],\n",
            "\n",
            "        [[ 0.0601, -0.0163, -0.0827,  0.0220]],\n",
            "\n",
            "        [[ 0.0674, -0.0147, -0.0922,  0.0287]],\n",
            "\n",
            "        [[ 0.0647, -0.0152, -0.0884,  0.0260]],\n",
            "\n",
            "        [[ 0.0719, -0.0134, -0.0978,  0.0337]],\n",
            "\n",
            "        [[ 0.0663, -0.0146, -0.0903,  0.0275]],\n",
            "\n",
            "        [[ 0.0578, -0.0161, -0.0788,  0.0198]],\n",
            "\n",
            "        [[ 0.0604, -0.0155, -0.0819,  0.0219]],\n",
            "\n",
            "        [[ 0.0745, -0.0123, -0.1006,  0.0368]],\n",
            "\n",
            "        [[ 0.0628, -0.0149, -0.0848,  0.0239]],\n",
            "\n",
            "        [[ 0.0670, -0.0140, -0.0902,  0.0279]],\n",
            "\n",
            "        [[ 0.0755, -0.0118, -0.1015,  0.0381]],\n",
            "\n",
            "        [[ 0.0584, -0.0152, -0.0785,  0.0200]],\n",
            "\n",
            "        [[ 0.0666, -0.0137, -0.0892,  0.0274]],\n",
            "\n",
            "        [[ 0.0633, -0.0142, -0.0846,  0.0241]],\n",
            "\n",
            "        [[ 0.0732, -0.0122, -0.0979,  0.0347]],\n",
            "\n",
            "        [[ 0.0660, -0.0136, -0.0879,  0.0266]],\n",
            "\n",
            "        [[ 0.0744, -0.0117, -0.0991,  0.0361]],\n",
            "\n",
            "        [[ 0.0607, -0.0142, -0.0805,  0.0216]],\n",
            "\n",
            "        [[ 0.0714, -0.0123, -0.0947,  0.0321]],\n",
            "\n",
            "        [[ 0.0767, -0.0109, -0.1017,  0.0391]],\n",
            "\n",
            "        [[ 0.0662, -0.0130, -0.0873,  0.0265]],\n",
            "\n",
            "        [[ 0.0733, -0.0116, -0.0968,  0.0343]],\n",
            "\n",
            "        [[ 0.0704, -0.0121, -0.0927,  0.0308]],\n",
            "\n",
            "        [[ 0.0692, -0.0123, -0.0908,  0.0294]],\n",
            "\n",
            "        [[ 0.0787, -0.0100, -0.1036,  0.0421]],\n",
            "\n",
            "        [[ 0.0636, -0.0130, -0.0829,  0.0238]],\n",
            "\n",
            "        [[ 0.0784, -0.0100, -0.1030,  0.0414]],\n",
            "\n",
            "        [[ 0.0652, -0.0126, -0.0847,  0.0251]],\n",
            "\n",
            "        [[ 0.0785, -0.0099, -0.1028,  0.0413]],\n",
            "\n",
            "        [[ 0.0692, -0.0118, -0.0897,  0.0290]],\n",
            "\n",
            "        [[ 0.0780, -0.0099, -0.1019,  0.0403]],\n",
            "\n",
            "        [[ 0.0774, -0.0100, -0.1009,  0.0393]],\n",
            "\n",
            "        [[ 0.0770, -0.0101, -0.1001,  0.0385]],\n",
            "\n",
            "        [[ 0.0738, -0.0107, -0.0955,  0.0341]],\n",
            "\n",
            "        [[ 0.0761, -0.0102, -0.0986,  0.0372]],\n",
            "\n",
            "        [[ 0.0792, -0.0094, -0.1028,  0.0420]],\n",
            "\n",
            "        [[ 0.0751, -0.0103, -0.0968,  0.0355]],\n",
            "\n",
            "        [[ 0.0734, -0.0105, -0.0944,  0.0334]],\n",
            "\n",
            "        [[ 0.0795, -0.0092, -0.1027,  0.0421]],\n",
            "\n",
            "        [[ 0.0758, -0.0100, -0.0974,  0.0363]],\n",
            "\n",
            "        [[ 0.0787, -0.0093, -0.1014,  0.0406]],\n",
            "\n",
            "        [[ 0.0815, -0.0084, -0.1052,  0.0459]],\n",
            "\n",
            "        [[ 0.0720, -0.0105, -0.0917,  0.0314]],\n",
            "\n",
            "        [[ 0.0815, -0.0084, -0.1049,  0.0456]],\n",
            "\n",
            "        [[ 0.0728, -0.0102, -0.0924,  0.0322]],\n",
            "\n",
            "        [[ 0.0717, -0.0104, -0.0907,  0.0308]],\n",
            "\n",
            "        [[ 0.0729, -0.0101, -0.0924,  0.0323]],\n",
            "\n",
            "        [[ 0.0827, -0.0079, -0.1061,  0.0480]],\n",
            "\n",
            "        [[ 0.0748, -0.0097, -0.0948,  0.0345]],\n",
            "\n",
            "        [[ 0.0828, -0.0078, -0.1061,  0.0482]],\n",
            "\n",
            "        [[ 0.0791, -0.0088, -0.1007,  0.0405]],\n",
            "\n",
            "        [[ 0.0759, -0.0094, -0.0960,  0.0358]],\n",
            "\n",
            "        [[ 0.0710, -0.0101, -0.0889,  0.0297]],\n",
            "\n",
            "        [[ 0.0829, -0.0077, -0.1059,  0.0480]],\n",
            "\n",
            "        [[ 0.0769, -0.0091, -0.0971,  0.0370]],\n",
            "\n",
            "        [[ 0.0795, -0.0085, -0.1008,  0.0409]],\n",
            "\n",
            "        [[ 0.0783, -0.0088, -0.0989,  0.0389]],\n",
            "\n",
            "        [[ 0.0824, -0.0078, -0.1047,  0.0462]],\n",
            "\n",
            "        [[ 0.0801, -0.0083, -0.1012,  0.0416]],\n",
            "\n",
            "        [[ 0.0803, -0.0083, -0.1015,  0.0420]],\n",
            "\n",
            "        [[ 0.0787, -0.0085, -0.0991,  0.0393]],\n",
            "\n",
            "        [[ 0.0744, -0.0092, -0.0928,  0.0333]],\n",
            "\n",
            "        [[ 0.0832, -0.0074, -0.1055,  0.0479]],\n",
            "\n",
            "        [[ 0.0724, -0.0095, -0.0898,  0.0309]],\n",
            "\n",
            "        [[ 0.0784, -0.0085, -0.0983,  0.0386]],\n",
            "\n",
            "        [[ 0.0762, -0.0088, -0.0949,  0.0355]],\n",
            "\n",
            "        [[ 0.0833, -0.0073, -0.1053,  0.0476]],\n",
            "\n",
            "        [[ 0.0740, -0.0091, -0.0916,  0.0326]],\n",
            "\n",
            "        [[ 0.0757, -0.0088, -0.0940,  0.0347]],\n",
            "\n",
            "        [[ 0.0815, -0.0077, -0.1024,  0.0436]],\n",
            "\n",
            "        [[ 0.0787, -0.0083, -0.0982,  0.0388]],\n",
            "\n",
            "        [[ 0.0733, -0.0091, -0.0904,  0.0317]],\n",
            "\n",
            "        [[ 0.0762, -0.0087, -0.0944,  0.0352]],\n",
            "\n",
            "        [[ 0.0759, -0.0087, -0.0939,  0.0348]],\n",
            "\n",
            "        [[ 0.0839, -0.0070, -0.1057,  0.0488]],\n",
            "\n",
            "        [[ 0.0763, -0.0086, -0.0943,  0.0352]],\n",
            "\n",
            "        [[ 0.0847, -0.0067, -0.1067,  0.0509]],\n",
            "\n",
            "        [[ 0.0795, -0.0080, -0.0988,  0.0398]],\n",
            "\n",
            "        [[ 0.0848, -0.0066, -0.1068,  0.0512]],\n",
            "\n",
            "        [[ 0.0761, -0.0085, -0.0937,  0.0348]],\n",
            "\n",
            "        [[ 0.0848, -0.0066, -0.1067,  0.0510]],\n",
            "\n",
            "        [[ 0.0850, -0.0065, -0.1069,  0.0517]],\n",
            "\n",
            "        [[ 0.0790, -0.0080, -0.0978,  0.0389]],\n",
            "\n",
            "        [[ 0.0823, -0.0073, -0.1028,  0.0446]],\n",
            "\n",
            "        [[ 0.0847, -0.0066, -0.1063,  0.0504]],\n",
            "\n",
            "        [[ 0.0779, -0.0081, -0.0960,  0.0371]],\n",
            "\n",
            "        [[ 0.0799, -0.0078, -0.0989,  0.0401]],\n",
            "\n",
            "        [[ 0.0790, -0.0079, -0.0975,  0.0386]],\n",
            "\n",
            "        [[ 0.0845, -0.0067, -0.1058,  0.0494]],\n",
            "\n",
            "        [[ 0.0830, -0.0071, -0.1035,  0.0457]],\n",
            "\n",
            "        [[ 0.0840, -0.0068, -0.1050,  0.0481]]], grad_fn=<TransposeBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(13, 1, 1)"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "trainPredict = model(trainX).detach().numpy()\n",
        "testPredict = model(testX).detach().numpy()\n",
        "trainPredict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQvolFR4sZkG",
        "outputId": "96196f2e-61cb-4ac6-ce08-634cc9483496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([13, 1]), (13, 1, 1))"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainY.shape, trainPredict.shape"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
